{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2175474,"status":"ok","timestamp":1716302330174,"user":{"displayName":"Elias El Haddad","userId":"10544210541935790041"},"user_tz":-120},"id":"CxenyXQldTjJ","outputId":"8f7e4b7a-b297-4cbb-82ed-966bc2640aca"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import pandas as pd\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from keras.layers import Embedding, Dense, LSTM, Dropout\n","from keras.models import Sequential\n","from keras.regularizers import l2\n","import tensorflow_model_optimization as tfmot\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","import os\n","\n","# Define and register the PrunableLSTM class\n","@tf.keras.utils.register_keras_serializable(package=\"Custom\", name=\"PrunableLSTM\")\n","class PrunableLSTM(LSTM, tfmot.sparsity.keras.PrunableLayer):\n","    def get_prunable_weights(self):\n","        return [self.cell.kernel, self.cell.recurrent_kernel]\n","\n","# Function to log model sizes\n","def get_model_size(model_name):\n","    model_path = f\"{model_name}.keras\"\n","    if os.path.exists(model_path):\n","        model_size = os.path.getsize(model_path) / 1024  # Size in KB\n","        return model_size\n","    else:\n","        return None\n","\n","# Function to log accuracy\n","def get_model_accuracy(history):\n","    train_acc = history.history['accuracy'][-1]\n","    val_acc = history.history['val_accuracy'][-1]\n","    return train_acc, val_acc\n","\n","# Function to plot model performance\n","def plot_model_performance(history, model_name):\n","    plt.figure(figsize=(12, 4))\n","\n","    # Plot accuracy\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n","    plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n","    plt.title(f\"{model_name} - Accuracy\")\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.legend()\n","\n","    # Plot loss\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n","    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n","    plt.title(f\"{model_name} - Loss\")\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend()\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def load_and_preprocess_data(file_path, max_words=10000, maxlen=66):\n","    data = pd.read_csv(file_path)\n","    tokenizer = Tokenizer(num_words=max_words)\n","    tokenizer.fit_on_texts(data[\"text\"])\n","    sequences = tokenizer.texts_to_sequences(data[\"text\"])\n","    data_padded = pad_sequences(sequences, maxlen=maxlen)\n","    label_encoder = LabelEncoder()\n","    integer_encoded = label_encoder.fit_transform(data[\"label\"])\n","    one_hot_labels = to_categorical(integer_encoded)\n","    x_train, x_temp, y_train, y_temp = train_test_split(\n","        data_padded, one_hot_labels, test_size=0.3, random_state=42\n","    )\n","    x_val, x_test, y_val, y_test = train_test_split(\n","        x_temp, y_temp, test_size=0.5, random_state=42\n","    )\n","    return x_train, x_val, x_test, y_train, y_val, y_test, len(label_encoder.classes_)\n","\n","# Load and preprocess data\n","file_path = \"sample_data/emotions.csv\"\n","x_train, x_val, x_test, y_train, y_val, y_test, num_classes = load_and_preprocess_data(file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_model(input_dim, output_dim, input_length, num_classes, use_pruning=False, use_clustering=False, pruning_schedule=None):\n","    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n","\n","    model = Sequential()\n","    if use_pruning:\n","        model.add(prune_low_magnitude(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length)))\n","        model.add(prune_low_magnitude(PrunableLSTM(64, kernel_regularizer=l2(0.001)), pruning_schedule=pruning_schedule))\n","        model.add(Dropout(0.5))\n","        model.add(prune_low_magnitude(Dense(num_classes, activation=\"softmax\")))\n","    elif use_clustering:\n","        clustering_params = {\n","            'number_of_clusters': 16,\n","            'cluster_centroids_init': tfmot.clustering.keras.CentroidInitialization.KMEANS_PLUS_PLUS\n","        }\n","        model.add(tfmot.clustering.keras.cluster_weights(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length), **clustering_params))\n","        model.add(tfmot.clustering.keras.cluster_weights(LSTM(64, kernel_regularizer=l2(0.001)), **clustering_params))\n","        model.add(Dropout(0.5))\n","        model.add(tfmot.clustering.keras.cluster_weights(Dense(num_classes, activation=\"softmax\"), **clustering_params))\n","    else:\n","        model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n","        model.add(LSTM(64, kernel_regularizer=l2(0.001)))\n","        model.add(Dropout(0.5))\n","        model.add(Dense(num_classes, activation=\"softmax\"))\n","\n","    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","    return model\n","\n","# Function to train the model with pruning and clustering options\n","def train_model(model, x_train, y_train, x_val, y_val, use_pruning=False, use_clustering=False):\n","    callbacks = []\n","    if use_pruning:\n","        callbacks = [\n","            tfmot.sparsity.keras.UpdatePruningStep(),\n","            tfmot.sparsity.keras.PruningSummaries(log_dir='/tmp/pruning_logs')\n","        ]\n","    history = model.fit(x_train, y_train, epochs=50, validation_data=(x_val, y_val), callbacks=callbacks)\n","    return history"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def quantize_model(model, model_name):\n","    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n","    quantized_tflite_model = converter.convert()\n","    quantized_model_path = f\"{model_name}.tflite\"\n","    with open(quantized_model_path, \"wb\") as f:\n","        f.write(quantized_tflite_model)\n","    model_size = os.path.getsize(quantized_model_path) / 1024  # Size in KB\n","    return quantized_model_path, model_size\n","\n","# Function to evaluate the TensorFlow Lite model\n","def evaluate_tflite_model(tflite_model_path, x_test, y_test):\n","    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n","    interpreter.allocate_tensors()\n","    input_details = interpreter.get_input_details()\n","    output_details = interpreter.get_output_details()\n","    predictions = []\n","    for i in range(len(x_test)):\n","        input_data = np.expand_dims(x_test[i], axis=0).astype(np.float32)\n","        interpreter.set_tensor(input_details[0]['index'], input_data)\n","        interpreter.invoke()\n","        output_data = interpreter.get_tensor(output_details[0]['index'])\n","        predictions.append(output_data)\n","    predictions = np.array(predictions).squeeze()\n","    accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1))\n","    return accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to plot comparison of model sizes and accuracies\n","def plot_comparison(teacher_size, pruned_size, clustered_size,\n","                    teacher_train_acc, teacher_val_acc, pruned_train_acc, pruned_val_acc,\n","                    clustered_train_acc, clustered_val_acc,\n","                    quantized_teacher_accuracy, quantized_pruned_accuracy, quantized_clustered_accuracy):\n","    # Data preparation\n","    sizes = [teacher_size, pruned_size, clustered_size]\n","    train_accuracies = [teacher_train_acc, pruned_train_acc, clustered_train_acc]\n","    val_accuracies = [teacher_val_acc, pruned_val_acc, clustered_val_acc]\n","    quantized_accuracies = [quantized_teacher_accuracy, quantized_pruned_accuracy, quantized_clustered_accuracy]\n","    models = ['Teacher', 'Pruned Teacher', 'Clustered Teacher']\n","\n","    # Plot sizes\n","    plt.figure(figsize=(14, 6))\n","\n","    plt.subplot(1, 3, 1)\n","    sns.barplot(x=models, y=sizes)\n","    plt.title('Model Sizes (KB)')\n","    plt.ylabel('Size (KB)')\n","\n","    # Plot training accuracies\n","    plt.subplot(1, 3, 2)\n","    sns.barplot(x=models, y=train_accuracies)\n","    plt.title('Training Accuracies')\n","    plt.ylabel('Accuracy')\n","\n","    # Plot validation accuracies\n","    plt.subplot(1, 3, 3)\n","    sns.barplot(x=models, y=val_accuracies)\n","    plt.title('Validation Accuracies')\n","    plt.ylabel('Accuracy')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Plot quantized models' accuracies\n","    fig = px.bar(x=models, y=quantized_accuracies, title=\"Quantized Models' Test Accuracy\", labels={'x':'Models', 'y':'Accuracy'})\n","    fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def summarize_results():\n","    teacher_size = get_model_size(\"teacher_model\")\n","    pruned_size = get_model_size(\"pruned_teacher_model\")\n","    clustered_size = get_model_size(\"clustered_teacher_model\")\n","\n","    teacher_train_acc, teacher_val_acc = get_model_accuracy(teacher_history)\n","    pruned_train_acc, pruned_val_acc = get_model_accuracy(pruned_history)\n","    clustered_train_acc, clustered_val_acc = get_model_accuracy(clustered_history)\n","\n","    summary = f\"\"\"\n","    Model Comparison Summary:\n","\n","    1. **Teacher Model:**\n","       - Size: {teacher_size:.2f} KB\n","       - Training Accuracy: {teacher_train_acc:.4f}\n","       - Validation Accuracy: {teacher_val_acc:.4f}\n","\n","    2. **Pruned Teacher Model:**\n","       - Size: {pruned_size:.2f} KB\n","       - Training Accuracy: {pruned_train_acc:.4f}\n","       - Validation Accuracy: {pruned_val_acc:.4f}\n","\n","    3. **Clustered Teacher Model:**\n","       - Size: {clustered_size:.2f} KB\n","       - Training Accuracy: {clustered_train_acc:.4f}\n","       - Validation Accuracy: {clustered_val_acc:.4f}\n","\n","    4. **Quantized Models Test Accuracy:**\n","       - Teacher Model: {quantized_teacher_accuracy:.4f}\n","       - Pruned Teacher Model: {quantized_pruned_accuracy:.4f}\n","       - Clustered Teacher Model: {quantized_clustered_accuracy:.4f}\n","\n","    Aim of the Project:\n","    The aim of this project was to explore and compare various model optimization techniques, specifically pruning and clustering, and to evaluate their impact on model size and performance. Pruning and clustering were applied to a base LSTM model, and the optimized models were further quantized to assess their effectiveness in reducing model size while maintaining accuracy.\n","\n","    Comparative Explanation:\n","    - The largest model is the **Teacher Model** with a size of {teacher_size:.2f} KB, achieving a validation accuracy of {teacher_val_acc:.4f}.\n","    - The **Pruned Teacher Model** reduced the size to {pruned_size:.2f} KB with a slight drop in validation accuracy to {pruned_val_acc:.4f}.\n","    - The **Clustered Teacher Model** also reduced the size to {clustered_size:.2f} KB, maintaining a validation accuracy of {clustered_val_acc:.4f}.\n","    - After quantization, the **Clustered Teacher Model** achieved the highest test accuracy of {quantized_clustered_accuracy:.4f}, showing the effectiveness of clustering and quantization in maintaining performance while reducing model size.\n","    \"\"\"\n","    print(summary)\n","\n","    plot_comparison(teacher_size, pruned_size, clustered_size,\n","                    teacher_train_acc, teacher_val_acc, pruned_train_acc, pruned_val_acc,\n","                    clustered_train_acc, clustered_val_acc,\n","                    quantized_teacher_accuracy, quantized_pruned_accuracy, quantized_clustered_accuracy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train the teacher model\n","teacher_model = create_model(input_dim=10000, output_dim=32, input_length=66, num_classes=num_classes)\n","teacher_history = train_model(teacher_model, x_train, y_train, x_val, y_val)\n","teacher_model.save(\"teacher_model.keras\")\n","\n","# Define the pruning schedule\n","pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(\n","    initial_sparsity=0.0,\n","    final_sparsity=0.5,\n","    begin_step=2000,\n","    end_step=10000\n",")\n","\n","# Train the pruned model\n","pruned_model = create_model(input_dim=10000, output_dim=32, input_length=66, num_classes=num_classes, use_pruning=True, pruning_schedule=pruning_schedule)\n","pruned_history = train_model(pruned_model, x_train, y_train, x_val, y_val, use_pruning=True)\n","\n","# Strip pruning and save the final pruned model\n","final_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n","final_pruned_model.save(\"pruned_teacher_model.keras\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Quantize the teacher model\n","quantized_teacher_model_path, quantized_teacher_size = quantize_model(teacher_model, \"quantized_teacher_model\")\n","quantized_teacher_accuracy = evaluate_tflite_model(quantized_teacher_model_path, x_test, y_test)\n","\n","# Quantize the pruned model\n","quantized_pruned_model_path, quantized_pruned_size = quantize_model(final_pruned_model, \"quantized_pruned_teacher_model\")\n","quantized_pruned_accuracy = evaluate_tflite_model(quantized_pruned_model_path, x_test, y_test)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train the clustered model\n","clustered_model = create_model(input_dim=10000, output_dim=32, input_length=66, num_classes=num_classes, use_clustering=True)\n","clustered_history = train_model(clustered_model, x_train, y_train, x_val, y_val, use_clustering=True)\n","\n","# Strip clustering and save the final clustered model\n","final_clustered_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n","final_clustered_model.save(\"clustered_teacher_model.keras\")\n","\n","# Quantize the clustered model\n","quantized_clustered_model_path, quantized_clustered_size = quantize_model(final_clustered_model, \"quantized_clustered_teacher_model\")\n","quantized_clustered_accuracy = evaluate_tflite_model(quantized_clustered_model_path, x_test, y_test)\n","\n","# Summarize results and plot comparison\n","summarize_results()"]}],"metadata":{"accelerator":"TPU","colab":{"authorship_tag":"ABX9TyPAm13eR2BpxjAQ7nSnfrOb","gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
